preprocessing:
  classes:
  - toxic
  - severe_toxic
  - obscene
  - threat
  - insult
  - identity_hate
  input_convertor: count_vectorization
  input_id_column: id
  input_testset: /Users/songyihe/Documents/Study/AI Projects/large-datasets/toxic-comments/mini_test.csv
  input_text_column: comment_text
  input_trainset: /Users/songyihe/Documents/Study/AI Projects/large-datasets/toxic-comments/mini_train.csv
  random_seed: 0
  split_ratio: 0.3
training:
  batch_normalization: true
  batch_size: 32
  dropout_rate: 0.5
  epochs: 2
  gradient_cliping: true
  learning_rate: 1.0
  model_name: naivebayes
  optimizer: sgd
predict:
  output_path: /Users/songyihe/Documents/Study/AI Projects/large-datasets/toxic-comments/mini_submission.csv
